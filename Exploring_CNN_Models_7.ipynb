{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM9hkrpmu+D0gU82FYMG9k6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keelinarseneault/ML-Engineering/blob/main/Exploring_CNN_Models_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dd2sY5gyEpNe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_2w3cdnhw2w",
        "outputId": "242c720a-f5f6-4842-c225-223bbad8b53f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/Users/karseneault/Desktop/train_data/'\n",
        "test_path = '/Users/karseneault/Desktop/test_data_v2/'"
      ],
      "metadata": {
        "id": "gC8tnQfvEyk_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('drive/MyDrive/train.csv')\n",
        "test = pd.read_csv('drive/MyDrive/test.csv')"
      ],
      "metadata": {
        "id": "cMJcSaZCE2Yd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['file_name', 'label']]\n",
        "train.columns = ['id', 'label']"
      ],
      "metadata": {
        "id": "68Xug_ZyE3JG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeDeW4SHFI6O",
        "outputId": "0ab1e883-3d27-4ea1-8ba6-b018a78d36ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(79950, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.value_counts('label'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AojQFDtlOnoN",
        "outputId": "62afd0fb-88b3-4820-cdc3-55791cedd7ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    39975\n",
            "1    39975\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compare CNN Architectures**"
      ],
      "metadata": {
        "id": "noOtFFLeoX1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConvNeXT:**"
      ],
      "metadata": {
        "id": "vEJ-iAd0onmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PyTorch\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "kUm3PDpVo-UP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/Images'"
      ],
      "metadata": {
        "id": "bOeGtoigqJ32"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_exists(id):\n",
        "    filepath = f\"drive/MyDrive/Images/{id}\"\n",
        "    return os.path.isfile(filepath)"
      ],
      "metadata": {
        "id": "-xlBbZ9BpC5N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train[\"id\"].apply(image_exists)]"
      ],
      "metadata": {
        "id": "dA3xreAJpG65"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHHe14XEpNzl",
        "outputId": "bf7cdf1c-2554-43df-8c6b-d70ed2df04ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11040, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take a random sample of the training set in order to train on a smaller set of images, while maintaining the balanced ratio between the two classes:**"
      ],
      "metadata": {
        "id": "zGMI4kxaqvYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = train.groupby(\"label\", group_keys=False).apply(lambda x:x.sample(frac=0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R09SM0sypXHl",
        "outputId": "16452420-db06-47eb-dc32-cbaf8bcca053"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-137aab85c240>:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  train_sample = train.groupby(\"label\", group_keys=False).apply(lambda x:x.sample(frac=0.5))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(\n",
        "    train_sample,\n",
        "    test_size=0.05,\n",
        "    random_state=42,\n",
        "    stratify=train_sample['label']\n",
        ")"
      ],
      "metadata": {
        "id": "mBVV8KVRp_nK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes of the splits\n",
        "print(f'Train shape: {train_df.shape}')\n",
        "print(f'Validation shape: {val_df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6H40J4asrXp",
        "outputId": "4ee91324-032c-414b-f3df-a644243da732"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (5244, 2)\n",
            "Validation shape: (276, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AIImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "KkRpzFyZpjAS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(232),  # Resize to match ConvNeXt preprocessing\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "_qx3UQXmpfGt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = AIImageDataset(train_df, root_dir=path, transform=train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Validation dataset and loader\n",
        "val_dataset = AIImageDataset(val_df, root_dir=path, transform=train_transforms)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "StE9uFGTplL0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ConvNeXt Base model\n",
        "model = models.convnext_base(weights=\"DEFAULT\")\n",
        "\n",
        "# Freeze all layers initially\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last two stages\n",
        "for param in model.features[-2:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace the classifier head with a custom one\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),  # Global average pooling\n",
        "    nn.Flatten(),                  # Flatten the tensor\n",
        "    nn.BatchNorm1d(1024),          # Add BatchNorm here\n",
        "    nn.Linear(1024, 512),          # First fully connected layer\n",
        "    nn.ReLU(),                     # Activation function\n",
        "    nn.Dropout(0.4),               # Dropout for regularization\n",
        "    nn.Linear(512, 2)              # Output layer (binary classification)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.features[-2:].parameters(), 'lr': 1e-5},  # Lower LR for backbone\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4}      # Higher LR for classifier\n",
        "])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.7)"
      ],
      "metadata": {
        "id": "WkVX01BSqYKO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model and criterion are on the GPU\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "\n",
        "# Training Loop\n",
        "epochs = 10\n",
        "train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []  # Removed val_f1s\n",
        "\n",
        "# Use Gradient Accumulation to simulate larger batch size without increasing memory usage\n",
        "grad_accum_steps = 2  # Accumulate gradients over 2 batches\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    epoch_accuracy = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, (data, label) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")):\n",
        "        # Move data and label to the GPU\n",
        "        data, label = data.to(device), label.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Accumulation: update weights only every grad_accum_steps\n",
        "        if (i + 1) % grad_accum_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        preds = output.argmax(dim=1)\n",
        "        acc = (preds == label).float().mean().item()\n",
        "        epoch_accuracy += acc\n",
        "\n",
        "    epoch_loss /= len(train_loader)\n",
        "    epoch_accuracy /= len(train_loader)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_accuracy = 0.0\n",
        "\n",
        "    with torch.no_grad():  # No need to calculate gradients during validation\n",
        "        for data, label in val_loader:\n",
        "            # Move data and label to the GPU\n",
        "            data, label = data.to(device), label.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = output.argmax(dim=1)\n",
        "            acc = (preds == label).float().mean().item()\n",
        "            val_accuracy += acc\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy /= len(val_loader)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0s32hOcqbvN",
        "outputId": "cee6f41f-9993-42a3-ee80-68f6b4ef16af"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 164/164 [01:33<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Train Loss: 0.4544 | Train Acc: 0.8197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Val Loss: 0.3206 | Val Acc: 0.8958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 164/164 [01:33<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] Train Loss: 0.2998 | Train Acc: 0.8845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] Val Loss: 0.2609 | Val Acc: 0.9042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 164/164 [01:32<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] Train Loss: 0.2404 | Train Acc: 0.9071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] Val Loss: 0.2131 | Val Acc: 0.8951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 164/164 [01:32<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] Train Loss: 0.2148 | Train Acc: 0.9167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] Val Loss: 0.2073 | Val Acc: 0.9271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 164/164 [01:34<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] Train Loss: 0.2011 | Train Acc: 0.9205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] Val Loss: 0.1730 | Val Acc: 0.9285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6: 100%|██████████| 164/164 [01:32<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] Train Loss: 0.1902 | Train Acc: 0.9243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] Val Loss: 0.1755 | Val Acc: 0.9299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7: 100%|██████████| 164/164 [01:32<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] Train Loss: 0.1770 | Train Acc: 0.9296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] Val Loss: 0.1742 | Val Acc: 0.9319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8: 100%|██████████| 164/164 [01:32<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] Train Loss: 0.1788 | Train Acc: 0.9264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] Val Loss: 0.1364 | Val Acc: 0.9528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9: 100%|██████████| 164/164 [01:32<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] Train Loss: 0.1786 | Train Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] Val Loss: 0.1616 | Val Acc: 0.9319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10: 100%|██████████| 164/164 [01:32<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] Train Loss: 0.1594 | Train Acc: 0.9408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] Val Loss: 0.1914 | Val Acc: 0.9250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **InceptionV3:**"
      ],
      "metadata": {
        "id": "_OIabZVOqfoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "RoDiZymWrcqS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/Images/'"
      ],
      "metadata": {
        "id": "ciUpAWRrEfe6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Make sure you have tensorflow installed\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(299, 299))  # Adjust target_size if needed\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    # No need to add batch dimension, done later\n",
        "    return img\n",
        "\n",
        "# Preprocess training data with tqdm progress bar\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for index, row in tqdm(train_df.iterrows(), total=train_df.shape[0], desc=\"Preprocessing images\"):\n",
        "    image_path = os.path.join(path, row['id'])\n",
        "    train_images.append(preprocess_image(image_path))\n",
        "    train_labels.append(row['label'])\n",
        "\n",
        "# Convert to NumPy arrays outside the loop\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n"
      ],
      "metadata": {
        "id": "U829xZ8xByTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e609fde3-0ff4-4de0-a8bb-1d002fec9638"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing images: 100%|██████████| 5244/5244 [54:15<00:00,  1.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess validation data using list comprehensions and pre-allocation\n",
        "val_image_paths = [os.path.join(path, image_id) for image_id in val_df['id']]\n",
        "val_images = np.empty((len(val_df), 299, 299, 3), dtype=np.float32)\n",
        "\n",
        "# Wrap the loop with tqdm for a progress bar\n",
        "for i, image_path in enumerate(tqdm(val_image_paths, desc=\"Preprocessing validation images\")):\n",
        "    val_images[i] = preprocess_image(image_path)[0]\n",
        "\n",
        "val_labels = val_df['label'].to_numpy()"
      ],
      "metadata": {
        "id": "gUZM08sLDnbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ece7cd-26f1-464d-b910-163653188380"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing validation images: 100%|██████████| 276/276 [03:47<00:00,  1.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "-FNB0cAXsCU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837b3e50-3c4f-4726-f680-e87c9343f2f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add layers\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)  # Prevent overfitting\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create final model\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "K6ygk8O3sOnR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3PM_pIcHsWtc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_images, train_labels, epochs=8, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "zrLz_XIOsZrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124bba9f-be9a-46c3-ed2f-97d5e6a04f72"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.9449 - loss: 0.1381 - val_accuracy: 0.5652 - val_loss: 3.2416\n",
            "Epoch 2/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.9325 - loss: 0.1530 - val_accuracy: 0.5870 - val_loss: 3.6289\n",
            "Epoch 3/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.9236 - loss: 0.1801 - val_accuracy: 0.5507 - val_loss: 3.1137\n",
            "Epoch 4/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9448 - loss: 0.1380 - val_accuracy: 0.5833 - val_loss: 4.0561\n",
            "Epoch 5/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9418 - loss: 0.1431 - val_accuracy: 0.5797 - val_loss: 3.9135\n",
            "Epoch 6/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9403 - loss: 0.1505 - val_accuracy: 0.5616 - val_loss: 3.5651\n",
            "Epoch 7/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9345 - loss: 0.1544 - val_accuracy: 0.5725 - val_loss: 3.7784\n",
            "Epoch 8/8\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.9323 - loss: 0.1612 - val_accuracy: 0.5833 - val_loss: 3.4553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
        "\n",
        "print(f\"Accuracy on train data: {train_accuracy:.2%} | Loss: {train_loss:.4f}\")"
      ],
      "metadata": {
        "id": "NpjPbv02s8rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04841133-5f20-45fe-ce65-2700ea212722"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9596 - loss: 0.1085\n",
            "Accuracy on train data: 96.45% | Loss: 0.0976\n"
          ]
        }
      ]
    }
  ]
}